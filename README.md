# Denoising Diffusion Probabilistic Model (DDPM) â€“ Oxford Pets

This project implements a **Denoising Diffusion Probabilistic Model (DDPM)** using an **upgraded UNet architecture** with **residual blocks, skip connections, sinusoidal timestep embeddings, and self-attention**, trained on the **Oxford-IIIT Pets dataset**.

The goal of the project is to generate realistic **64Ã—64 RGB images of pets** by learning to iteratively denoise Gaussian noise.

---

## ðŸ“Œ Key Features

- Denoising Diffusion Probabilistic Model (DDPM)
- UNet backbone with encoderâ€“decoder structure
- Residual blocks for stable deep training
- Skip connections to preserve spatial details
- Sinusoidal timestep embeddings
- Self-attention at intermediate resolutions
- Training checkpointing and resume support
- Visualization of generated samples and loss curves

---

## ðŸ“‚ Dataset

**Oxford-IIIT Pets Dataset**

- RGB images of cats and dogs
- Images resized to **64Ã—64**
- Pixel values normalized to **[-1, 1]**
- Used in an **unconditional** setting (labels ignored)

---

## ðŸ§  Model Architecture Overview

The model follows a **UNet-based architecture**, adapted for diffusion models.

### ðŸ”¹ High-level Structure

Input Image (x_t)
â†“
Encoder (Downsampling path)
â†“
Bottleneck
â†“
Decoder (Upsampling path)
â†“
Predicted Noise Îµ_Î¸(x_t, t)


---

## ðŸ”¹ UNet Encoder

- Consists of multiple **Residual Blocks**
- Spatial resolution decreases:  
  `64Ã—64 â†’ 32Ã—32 â†’ 16Ã—16 â†’ 8Ã—8 â†’ 4Ã—4`
- Channel depth increases:  
  `3 â†’ 128 â†’ 256 â†’ 512`
- **Self-attention layers** are applied at:
  - 32Ã—32
  - 16Ã—16
  - 8Ã—8

---

## ðŸ”¹ Bottleneck

- Operates at the lowest spatial resolution (4Ã—4)
- Contains:
  - Residual blocks
  - A self-attention layer
- Captures **global image structure** before reconstruction

---

## ðŸ”¹ UNet Decoder

- Upsamples feature maps back to the original resolution
- Uses **skip connections** from the encoder
- Skip connections help preserve:
  - Edges
  - Shapes
  - Fine spatial details

---

## ðŸ”¹ Residual Blocks

Each residual block:
- Applies normalization, activation, and convolution
- Adds the input back to the output (residual connection)
- Improves gradient flow and training stability
- Allows deeper networks without vanishing gradients

---

## ðŸ”¹ Self-Attention

Self-attention layers allow the model to:
- Capture **long-range dependencies**
- Relate distant parts of the image
- Improve global coherence (e.g., face structure, body shape)

This is especially useful for image generation where context matters.

---

## ðŸ”¹ Timestep Embedding

- Each diffusion step `t` is encoded using **sinusoidal embeddings**
- Embeddings are passed through an MLP
- Injected into every residual block
- Allows the network to learn **how much noise to remove at each timestep**


## ðŸ”„ Diffusion Process

### Forward Process
Gradually adds Gaussian noise to images over `T` steps:
x_t = âˆšÎ±Ì„_t Â· x_0 + âˆš(1 âˆ’ Î±Ì„_t) Â· Îµ


### Reverse Process
The model learns to predict the noise and remove it step by step:
x_t â†’ x_{t-1} â†’ ... â†’ x_0
